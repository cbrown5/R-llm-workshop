[["index.html", "Quality R analysis with large language models Chapter 1 Summary 1.1 About Chris", " Quality R analysis with large language models CJ Brown (c.j.brown@utas.edu.au) 2025-05-17 Chapter 1 Summary If you are using R you are probably using language models (e.g. ChatGPT) to help you write code, but are you using them in the most effective way? Language models have different biases to humans and so make different types of errors. This 1-day workshop will cover how to use language models to learn R and conduct reliable environmental analyses. We will cover: Pros and cons of different tools from the simple interfaces like ChatGPT to advanced tools that can run and test code by themselves and keep going until the analysis is complete (and even written up). Best practice prompting techniques that can dramatically improve model performance for complex statistical applications Applying language models to common environmental applications such as GLMs, multivariate statistics and Bayesian statistics Copyright and ethical issues We’ll finish up with a discussion of what large language models mean for analysis and the scientific process. Requirements for interactive workshop: Laptop with R, Rstudio and VScode installed. Please see software instructions below. 1.0.0.1 Who should take this workshop? The workshop is for: anyone who currently uses R, from intermittent users to experienced professionals. The workshop is not suitable for those that need an introduction to R and I’ll assume students know at least what R does and are able to do tasks like read in data and create plots. 1.1 About Chris I’m an Associate Professor of Fisheries Science at University of Tasmania and an Australian Research Council Future Fellow. I specialise in data analysis and modelling, skills I use to better inform environmental decision makers. R takes me many places and I’ve worked with marine ecosystems from tuna fisheries to mangrove forests. I’m an experienced teacher of R. I have taught R to 100s people over the years, from the basics to sophisticated modelling and for everyone from undergraduates to my own supervisors. "],["course-outline.html", "Chapter 2 Course outline 2.1 Software you’ll need for this workshop 2.2 Software licenses 2.3 R packages you’ll need for this workshop 2.4 Data", " Chapter 2 Course outline 2.0.1 Introduction to LLMs for R 9-10am In this presentation I’ll cover how LLMs work, best practices prompt engineering, software, applications for R users and ethics. 2.0.2 Part 1 LLM prompting fundamentals 10-10:30am Start of practical material We’ll cover LLM prompting theory through practical examples. This section will give you a deep understanding of how chatbots work and teach you some advanced prompting skills. Software: VScode with R or Rstudio, ellmer package, API license. 2.0.2.1 Tea break: 10:30-10:45 2.0.2.2 Understanding how LLMs work 10:45-11:30am Intro to LLM technology, including token input and output, system and user messages, temperature, model choice and more. We’ll make our own specialised stats chatbot with R. 2.0.2.3 Advanced prompting We’ll continue with our chatbot to make it a specialist in statistics. We’ll learn some advanced prompting skills like structured data, parsing and tool construction. 2.0.2.4 Ethics and copyright Discussion. 2.0.3 Part 2 Github copilot for R 11:30-12:00pm I’ll show you how you can most effectively use github copilot to plan, code and write up your data analysis and modelling. Software: VScode with R and github copilot license + extension for copilot. 2.0.3.1 Best practices project setup How to be organized to maximise LLM effectiveness. Version control. 2.0.3.2 Lunch: 12-1pm After lunch we’ll continue with Github Copilot. 2.0.3.3 Inline code editing 2.0.3.4 Planning your project with Ask mode 2.0.3.5 Creating your code with Edit mode 2.0.3.6 Automated workflows with Agent mode 2.0.3.7 Tea break 2:45-3:00pm 2.0.4 Part 3 Advanced LLM agents 3:00-3:30pm Software: VScode with R, Roo code, API license. 2.0.4.1 Roo code Fully automated workflows. 2.0.4.2 Cost and security 2.0.4.3 Conclusion 3:30pm-4:00pm We’ll discuss as a group what LLMs mean for the way we do science, and creating community standards. 2.1 Software you’ll need for this workshop Save some time for set-up, there is a bit to it. You may also need ITs help if your computer is locked down. R of course, (4.2.2 or later) VScode It takes a bit of time and IT knowledge and setting up to connect VScode to R. So don’t leave that to the last minute See my installation instructions Once you have VScode, make sure you get these extensions (which can be found by clicking the four squares in the left hand menu bar): GitHub Copilot, GitHub Copilot Chat If you can’t get VScode to work with R you are still welcome to join. Most of the morning session can be done in Rstudio. In the afternoon you’ll need VScode if you want to try what I am teaching. 2.1.1 Optional software RStudio. You can do some of this workshop in Rstudio. But you’ll get more out of it if you use VScode. If you are using Rstudio, make sure you get a Github Copilot account and connect it to Rstudio. 2.1.1.1 Optional VScode extensions Web Search for Copilot (once installed, follow the instructions to set up your API key, I use Tavily because it has a free tier). Roo code extension for VScode. Markdown preview enhanced Let’s you view markdown files in a pane with cmd(cntrl)-shift-V Radian terminal I also recommend installing radian terminal. This makes your terminal for R much cleaner, has autocomplete and seems to help with some common issues. 2.2 Software licenses Github copilot Go to their page to sign-up. The free tier is fine. You can also get free Pro access as a student or professor (requires application). API key and account with LLM provider You will need API (application programming interface) access to an LLM to do all the examples in this workshop. This will allow us to interact with LLMs directly via R code. API access is on a pay per token basis. You will need to create an account with one of the below providers and then buy some credits (USD10 should be sufficient). Here are some popular choices: OpenRouter (recommended as gives you flexible access to lots of models) Anthropic OpenAI Once you have your API key, keep it secret. It’s a password. Be careful not to push it to aa github repo accidently. 2.3 R packages you’ll need for this workshop install.packages(c(\"vegan\", \"ellmer\",\"tidyverse\") INLA for Bayesian computation. Use the link, its not on cran. 2.4 Data Not yet complete… We’ll work with some benthic cover data, direct links to csv files are here: text files for 2 papers. time-series data? "],["introduction-to-llms-for-r-1.html", "Chapter 3 Introduction to LLMs for R", " Chapter 3 Introduction to LLMs for R Time: 9-10am In this presentation I’ll cover how LLMs work, best practices prompt engineering, software, applications for R users and ethics. This chapter provides an overview of: How Large Language Models (LLMs) function and their capabilities Best practices for prompt engineering when working with R Software options available for R users to interact with LLMs Practical applications of LLMs for R programming and data analysis Ethical considerations when using LLMs for scientific work We’ll explore how LLMs can enhance your R workflow, from code generation to data analysis assistance, while maintaining scientific rigor and reproducibility. "],["part-1-llm-prompting-fundamentals-1.html", "Chapter 4 Part 1: LLM prompting fundamentals", " Chapter 4 Part 1: LLM prompting fundamentals Time: 10-10:30am Start of practical material We’ll cover LLM prompting theory through practical examples. This section will give you a deep understanding of how chatbots work and teach you some advanced prompting skills. Software requirements: VScode with R or Rstudio, ellmer package, API license. This chapter introduces the fundamental concepts of prompting LLMs effectively: Understanding the basics of how LLMs interpret and respond to prompts Learning to structure prompts for optimal results Practical examples demonstrating effective prompting techniques Hands-on exercises to develop your prompting skills Through these practical examples, you’ll gain insight into how LLMs process information and how to craft prompts that yield the most accurate and useful responses for R programming and data analysis tasks. "],["understanding-how-llms-work-1.html", "Chapter 5 Understanding how LLMs work", " Chapter 5 Understanding how LLMs work Time: 10:45-11:30am Intro to LLM technology, including token input and output, system and user messages, temperature, model choice and more. We’ll make our own specialised stats chatbot with R. This chapter explores the technical aspects of LLMs: Token-based processing: how LLMs interpret and generate text The role of system messages vs. user messages in controlling LLM behavior Temperature and other parameters that affect output variability Differences between various LLM models and how to choose the right one Hands-on exercise: Creating a specialized statistics chatbot using R By understanding these technical foundations, you’ll be better equipped to leverage LLMs effectively for your R programming and data analysis tasks, and to troubleshoot when you’re not getting the results you expect. We’ll use the ellmer package to interact with LLMs directly from R, allowing us to create a customized statistics assistant that can help with data analysis tasks. "],["advanced-prompting-1.html", "Chapter 6 Advanced prompting", " Chapter 6 Advanced prompting We’ll continue with our chatbot to make it a specialist in statistics. We’ll learn some advanced prompting skills like structured data, parsing and tool construction. This chapter builds on the fundamentals to explore more sophisticated prompting techniques: Creating prompts that generate structured data (JSON, CSV, etc.) Techniques for parsing and processing LLM outputs in R Building tools that leverage LLMs for specific statistical tasks Chain-of-thought prompting for complex reasoning Few-shot learning and example-based prompting Through practical examples, you’ll learn how to: Guide LLMs to provide responses in specific formats that are easy to process with R Create reusable prompting templates for common statistical tasks Implement error handling and validation for LLM outputs Combine multiple prompts to solve complex problems These advanced techniques will help you create more reliable and effective LLM-powered tools for your R workflows, particularly for statistical analysis and data science tasks. "],["ethics-and-copyright-1.html", "Chapter 7 Ethics and copyright 7.1 Model biases 7.2 Energy use 7.3 Copyright 7.4 Managing data privacy", " Chapter 7 Ethics and copyright This chapter addresses important ethical and legal considerations when using LLMs for R programming and data analysis: 7.1 Model biases Understanding inherent biases in LLMs Recognizing when biases might affect statistical analysis Techniques for mitigating bias in LLM-generated code and analysis 7.2 Energy use Environmental impact of LLM usage Balancing computational efficiency with analytical needs Strategies for reducing the carbon footprint of LLM-powered workflows 7.3 Copyright Legal considerations when using LLM-generated code Understanding the licensing implications of LLM outputs Best practices for attribution and documentation 7.4 Managing data privacy Strategies for using LLMs without exposing sensitive data Techniques for getting LLMs to write code for analysis without showing them the data Keeping data in separate directories and other practical approaches Considerations for research involving human subjects or proprietary information This discussion will help you develop responsible practices for incorporating LLMs into your scientific workflow while respecting ethical, legal, and privacy considerations. "],["part-2-github-copilot-for-r-1.html", "Chapter 8 Part 2: Github copilot for R", " Chapter 8 Part 2: Github copilot for R Time: 11:30-12:00pm I’ll show you how you can most effectively use github copilot to plan, code and write up your data analysis and modelling. Software requirements: VScode with R and github copilot license + extension for copilot. This chapter introduces GitHub Copilot as a powerful tool for R programmers: Overview of GitHub Copilot and how it differs from other LLM tools Setting up and configuring Copilot for optimal R programming assistance Understanding Copilot’s strengths and limitations for data analysis tasks Strategies for effectively collaborating with Copilot on R projects We’ll explore how Copilot can accelerate your R development process by: - Suggesting code completions based on context - Generating entire functions and code blocks - Helping with documentation and commenting - Assisting with debugging and error resolution Through practical demonstrations, you’ll learn how to leverage Copilot’s capabilities while maintaining control over your code’s quality and correctness, particularly for statistical analysis and data science applications. "],["best-practices-project-setup-1.html", "Chapter 9 Best practices project setup 9.1 Project organization 9.2 Version control with Git 9.3 R project setup", " Chapter 9 Best practices project setup How to be organized to maximise LLM effectiveness. Version control. This chapter focuses on establishing an optimal project structure and workflow to get the most out of LLMs in your R projects: 9.1 Project organization Directory structures that facilitate LLM assistance Documentation practices that improve LLM understanding of your code Naming conventions and code organization principles Creating effective README files and project documentation 9.2 Version control with Git Basic Git workflow for R projects How version control enhances collaboration with LLMs Using Git to track changes made with LLM assistance Best practices for committing LLM-generated code 9.3 R project setup Using RStudio projects or VSCode workspaces Setting up reproducible environments with renv or packrat Creating and maintaining package dependency documentation Organizing data, code, and output directories By implementing these best practices, you’ll create a development environment where LLMs can provide more accurate and contextually relevant assistance, leading to more efficient and reliable R programming workflows. "],["inline-code-editing-1.html", "Chapter 10 Inline code editing 10.1 Understanding inline suggestions 10.2 Guiding Copilot with comments 10.3 Common patterns for R programming 10.4 Troubleshooting and refinement", " Chapter 10 Inline code editing This chapter explores techniques for using GitHub Copilot’s inline code editing capabilities to enhance your R programming workflow: 10.1 Understanding inline suggestions How Copilot generates inline code suggestions Interpreting and evaluating Copilot’s suggestions Accepting, modifying, or rejecting suggestions effectively Keyboard shortcuts and efficiency tips 10.2 Guiding Copilot with comments Writing effective comments to steer Copilot’s suggestions Using natural language to describe your coding intentions Documenting complex statistical procedures for better suggestions Balancing detail and brevity in comments 10.3 Common patterns for R programming Data manipulation with tidyverse Statistical modeling and analysis Data visualization with ggplot2 Working with specialized R packages 10.4 Troubleshooting and refinement Strategies when Copilot provides incorrect or suboptimal suggestions Iterative refinement of code with Copilot’s assistance Handling R-specific syntax and idioms Adapting to Copilot’s learning curve Through practical examples and hands-on exercises, you’ll learn to seamlessly integrate Copilot’s inline suggestions into your R coding process, significantly accelerating your development while maintaining code quality. "],["planning-your-project-with-ask-mode-1.html", "Chapter 11 Planning your project with Ask mode 11.1 Introduction to Ask mode 11.2 Project planning with Ask mode 11.3 Asking effective questions 11.4 Implementing Ask mode suggestions", " Chapter 11 Planning your project with Ask mode This chapter explores how to effectively use GitHub Copilot’s Ask mode to plan and structure your R projects: 11.1 Introduction to Ask mode What is Ask mode and how it differs from inline suggestions Accessing and using Ask mode in VSCode Understanding the capabilities and limitations of Ask mode When to use Ask mode vs. other Copilot features 11.2 Project planning with Ask mode Breaking down complex data analysis tasks Creating project roadmaps and development plans Identifying necessary packages and dependencies Structuring your analysis workflow 11.3 Asking effective questions Formulating clear and specific questions Providing sufficient context for accurate responses Iterative questioning strategies Domain-specific questions for statistical analysis 11.4 Implementing Ask mode suggestions Translating high-level advice into concrete code Evaluating and adapting suggested approaches Combining Ask mode with inline coding Documentation based on Ask mode explanations Through practical examples, you’ll learn how to leverage Ask mode as a planning and problem-solving tool that can help you approach complex R programming tasks with greater clarity and structure. "],["creating-your-code-with-edit-mode-1.html", "Chapter 12 Creating your code with Edit mode 12.1 Understanding Edit mode 12.2 Code generation strategies 12.3 Code transformation techniques 12.4 Quality control and refinement", " Chapter 12 Creating your code with Edit mode This chapter explores how to leverage GitHub Copilot’s Edit mode to efficiently create and modify R code: 12.1 Understanding Edit mode What is Edit mode and how it differs from other Copilot features Accessing and using Edit mode in VSCode Edit mode’s capabilities for code generation and transformation When to use Edit mode in your R workflow 12.2 Code generation strategies Creating functions and code blocks from natural language descriptions Generating data manipulation pipelines Building statistical models and analysis scripts Creating data visualization code 12.3 Code transformation techniques Refactoring existing R code for better performance or readability Converting between base R and tidyverse approaches Translating code between different statistical frameworks Adapting code examples to your specific needs 12.4 Quality control and refinement Evaluating and testing generated code Iterative improvement through Edit mode Handling edge cases and error conditions Ensuring code readability and maintainability Through hands-on examples, you’ll learn to use Edit mode as a powerful tool for both creating new R code and transforming existing code, significantly accelerating your development process while maintaining high-quality, reliable code. "],["automated-workflows-with-agent-mode-1.html", "Chapter 13 Automated workflows with Agent mode 13.1 Introduction to Agent mode 13.2 Creating automated workflows 13.3 Common R workflow applications 13.4 Troubleshooting and optimization", " Chapter 13 Automated workflows with Agent mode This chapter explores how to use GitHub Copilot’s Agent mode to create automated workflows for R programming and data analysis: 13.1 Introduction to Agent mode What is Agent mode and how it differs from other Copilot features Accessing and using Agent mode in VSCode Understanding the capabilities and limitations of Agent mode When to use Agent mode in your R workflow 13.2 Creating automated workflows Defining tasks for Agent mode to accomplish Breaking down complex analyses into manageable steps Setting up appropriate contexts and environments Monitoring and guiding Agent mode’s progress 13.3 Common R workflow applications Data cleaning and preprocessing Exploratory data analysis Statistical modeling and hypothesis testing Report generation and visualization 13.4 Troubleshooting and optimization Handling errors and unexpected results Providing additional context when needed Refining workflow definitions for better results Balancing automation with human oversight Through practical demonstrations, you’ll learn how to leverage Agent mode to automate repetitive or complex R programming tasks, allowing you to focus on higher-level analysis and interpretation while maintaining control over the quality and correctness of your code. "],["part-3-advanced-llm-agents-1.html", "Chapter 14 Part 3: Advanced LLM agents 14.1 Evolution of LLM agents 14.2 Agent capabilities for R 14.3 Integration with R workflows 14.4 Practical considerations", " Chapter 14 Part 3: Advanced LLM agents Time: 3:00-3:30pm Software requirements: VScode with R, Roo code, API license. This chapter introduces advanced LLM agents that go beyond GitHub Copilot’s capabilities: 14.1 Evolution of LLM agents How LLM agents differ from simple code completion tools The spectrum of automation in LLM-assisted programming Understanding agent architectures and capabilities Current state-of-the-art in LLM agents for R programming 14.2 Agent capabilities for R Code generation and modification Reasoning about complex statistical problems Autonomous debugging and error correction Documentation and explanation generation 14.3 Integration with R workflows Connecting agents to your development environment API-based interactions with LLM agents Batch processing vs. interactive assistance Combining multiple agents for complex tasks 14.4 Practical considerations Computational requirements and performance Cost structures and optimization strategies Privacy and security implications Evaluating agent output quality This chapter provides a foundation for understanding more sophisticated LLM agents, preparing you for the next chapter’s focus on Roo code as a specific implementation of advanced agent technology for R programming. "],["roo-code-1.html", "Chapter 15 Roo code 15.1 Introduction to Roo code 15.2 Autonomous R programming with Roo 15.3 Advanced use cases for R 15.4 Best practices and workflow integration", " Chapter 15 Roo code Fully automated workflows. This chapter explores Roo code as a powerful tool for creating fully automated workflows in R: 15.1 Introduction to Roo code What is Roo code and how it differs from other LLM tools Setting up and configuring Roo code in VSCode Understanding Roo’s capabilities and limitations The architecture behind Roo’s automation capabilities 15.2 Autonomous R programming with Roo How Roo interprets task descriptions and requirements Roo’s approach to generating, testing, and refining code Monitoring and interacting with Roo during code generation Evaluating and validating Roo-generated solutions 15.3 Advanced use cases for R End-to-end data analysis pipelines Complex statistical modeling and inference Custom visualization development Package development and documentation 15.4 Best practices and workflow integration Providing effective task descriptions Balancing autonomy with guidance Incorporating Roo into existing development workflows Version control and collaboration with Roo-generated code Through practical demonstrations, you’ll learn how to leverage Roo code to automate sophisticated R programming tasks, potentially saving hours of development time while maintaining high-quality, reliable code. "],["cost-and-security-1.html", "Chapter 16 Cost and security 16.1 Cost considerations 16.2 Security implications 16.3 Best practices for secure usage 16.4 Institutional considerations", " Chapter 16 Cost and security This chapter addresses important practical considerations when using LLMs for R programming: 16.1 Cost considerations Understanding the pricing models of different LLM providers API costs vs. subscription models Strategies for optimizing token usage Balancing cost with capability requirements Budgeting for LLM usage in research and professional contexts 16.2 Security implications Data privacy concerns when using LLMs Understanding what data is sent to LLM providers Risks of exposing sensitive or proprietary information Compliance considerations for different industries and research contexts 16.3 Best practices for secure usage Managing API keys and credentials Sanitizing inputs to remove sensitive information Local vs. cloud-based LLM solutions Auditing and monitoring LLM interactions 16.4 Institutional considerations Developing organizational policies for LLM usage Training researchers and staff on secure practices Documentation and transparency requirements Balancing innovation with risk management This chapter provides practical guidance for managing the financial and security aspects of incorporating LLMs into your R workflow, helping you make informed decisions about when and how to use these powerful tools. "],["conclusion-1.html", "Chapter 17 Conclusion 17.1 Workshop summary 17.2 The changing landscape of scientific computing 17.3 Developing community standards 17.4 Future directions", " Chapter 17 Conclusion Time: 3:30pm-4:00pm We’ll discuss as a group what LLMs mean for the way we do science, and creating community standards. This chapter synthesizes the key insights from the workshop and explores the broader implications of LLMs for scientific practice: 17.1 Workshop summary Recap of key concepts and techniques covered Integration of different LLM tools and approaches Progression from basic prompting to advanced autonomous agents Practical applications for R programming and data analysis 17.2 The changing landscape of scientific computing How LLMs are transforming research workflows Potential impacts on reproducibility and transparency Changes in skill requirements and education Democratization of advanced programming capabilities 17.3 Developing community standards Ethical considerations for LLM use in scientific research Documentation and reporting practices Peer review in the age of LLM-assisted research Balancing innovation with methodological rigor 17.4 Future directions Emerging trends in LLM technology Potential developments in R-specific LLM tools Opportunities for community contribution and development Preparing for the next generation of AI-assisted data science This concluding discussion encourages critical reflection on how we can harness the power of LLMs while maintaining the integrity and quality of scientific research and analysis. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
